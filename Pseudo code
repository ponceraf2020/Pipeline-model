# Import data
import pandas as pd
df = pd.read_excel("GSE24427 Dataset 5.xlsx")

# Define inputs and output
from sklearn.preprocessing import LabelEncoder
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values
le = LabelEncoder()
y = le.fit_transform(y)
le.classes_
le.transform(['high', 'low', 'medium'])

# Plot data
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(17, 12))
plt.subplot(331)
sns.scatterplot(data=df, x=df.iloc[0:24, 0], y=df.iloc[0:24, 20], hue='Responder')
plt.subplot(332)
sns.scatterplot(data=df, x=df.iloc[0:24, 1], y=df.iloc[0:24, 21], hue='Responder')
plt.subplot(333)
sns.scatterplot(data=df, x=df.iloc[0:24, 2], y=df.iloc[0:24, 22], hue='Responder')
plt.subplot(334)
sns.scatterplot(data=df, x=df.iloc[0:24, 3], y=df.iloc[0:24, 23], hue='Responder')
plt.subplot(335)
sns.scatterplot(data=df, x=df.iloc[0:24, 4], y=df.iloc[0:24, 24], hue='Responder')

#Split data into training and testing
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = \
    train_test_split(X, y, 
                     test_size=0.20,
                     stratify=y,
                     random_state=1)
                     
# Define teh pipeline prediction model
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.neural_network import MLPClassifier
from sklearn.pipeline import make_pipeline

n_components = range(1, 15)
scores_pipe = []
for n in n_components:
    pipe_mlp = make_pipeline(StandardScaler(),
                        PCA(n_components=n),
                        MLPClassifier(
                                    solver="adam",
                                    activation='relu',
                                    random_state=1,
                                    learning_rate_init=0.01))
    pipe_mlp.fit(X_train, y_train)
    y_pred = pipe_mlp.predict(X_test)
    scores_pipe.append(pipe_mlp.score(X_test, y_test))

# Plot the optimal n_components for PCA
plt.plot(n_components, scores_pipe, 'r--')
plt.xlabel('Value of n_components for PCA')
plt.ylabel('Testing Accuracy')

# Evaluate the model for n_components=10
pipe_mlp = make_pipeline(StandardScaler(),
                        PCA(n_components=10),
                        MLPClassifier(
                                    solver="adam",
                                    activation='relu',
                                    random_state=1,
                                    learning_rate_init=0.01))
pipe_mlp.fit(X_train, y_train)
y_pred = pipe_mlp.predict(X_test)
print('Test Accuracy: %.3f' % pipe_mlp.score(X_test, y_test))

# Performance evaluation
import numpy as np
from sklearn.model_selection import StratifiedKFold
kfold = StratifiedKFold(n_splits=8).split(X_train, y_train)
scores_cv = []
for k, (train, test) in enumerate(kfold):
    pipe_mlp.fit(X_train[train], y_train[train])
    score = pipe_mlp.score(X_train[test], y_train[test])
    scores_cv.append(score)
    print('Fold: %2d, Class dist.: %s, Acc: %.3f' % (k+1,
          np.bincount(y_train[train]), score))
print('\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores_cv), np.std(scores_cv)))

# Compute confusion matrix
from sklearn.metrics import confusion_matrix
pipe_mlp.fit(X_train, y_train)
y_pred = pipe_mlp.predict(X_test)
confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)

fig, ax = plt.subplots()
ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)
for i in range(confmat.shape[0]):
    for j in range(confmat.shape[1]):
        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')

plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.tight_layout()
plt.show()
